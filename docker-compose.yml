version: "3.7"

# port : 호스트 OS와 컨테이너의 포트를 바인딩 시켜준다.
# expose : 호스트 OS에 포트를 공개하지 않고, 컨테이너만 공개
#    - 호스트 OS에 직접 연결되지 않고 링크등으로 연결된 컨테이너-컨테이너간의 통신만 필요한 경우 사용
# depends_on : 서비스간의 종속성 순서대로 서비스를 시작
# container_name : 컨테이너 이름을 지정
# volumes : docker 컨테이너의 생명 주기와 관계없이 데이터를 영속적으로 저장

services:
  backend:
    container_name: backend
    # env_file: ./.env
    build: ./backend/.
    image: backend
    volumes:
      - ./backend/:/backend/
      - static_volume:/backend/static # <-- bind the static volume
    stdin_open: true
    tty: true
    ports:
      - 8000:8000
    command: sh -c "python manage.py migrate && gunicorn --bind :8000 backend.wsgi:application"
    networks:
      - backend_network
    environment:
      - CHOKIDAR_USEPOLLING=true
      - DJANGO_SETTINGS_MODULE=backend.settings
    expose:
      - 8000

  frontend:
    container_name: frontend
    build: ./frontend
    volumes:
      - ./frontend/:/frontend
      - build_folder:/frontend/dist
      - ./frontend/node_modules/:/frontend/node_modules
    tty: true

  backend-server:
    container_name: nginx-back
    build:
      context: ./nginx/.
      dockerfile: Dockerfile
    volumes:
      - static_volume:/backend/static # <-- bind the static volume
      - build_folder:/var/www/frontend
      - ./nginx/log:/var/log/nginx # nginx log path (require same option on nginx container)
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - backend
    expose:
      - 80
      - 443
    networks:
      - backend_network

  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    ports:
      - 9090:9090
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=200h"
      - "--web.enable-lifecycle"
    depends_on:
      - backend
    networks:
      - backend_network
    expose:
      - 9090

  grafana:
    image: grafana/grafana:latest
    ports:
      - 3333:3000
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=grafana
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - backend
      - prometheus
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    networks:
      - backend_network

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter # 컨테이너를 stop시키기 전까지 항상 재시작
    restart: unless-stopped
    ports:
      - 9100:9100
    networks:
      - backend_network

  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - 9093:9093
    restart: always
    volumes:
      - ./alertmanager/:/etc/alertmanager/
    networks:
      - backend_network

    command:
      - "--config.file=/etc/alertmanager/config.yml"
      - "--storage.path=/alertmanager"

  rabbitmq:
    image: rabbitmq:3.7-management
    container_name: "rabbitmq"
    ports:
      # Expose the port for the worker to add/get tasks
      - 5672:5672
      # OPTIONAL: Expose the GUI port
      - 15672:15672
    expose:
      - 5672
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672//
    depends_on:
      - backend
    networks:
      - backend_network
    tty: true

  celery:
    container_name: celery_service
    image: backend
    volumes:
      - ./backend:/backend
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672//
    command: >
      bash -c "celery -A backend worker --loglevel=info --pool=solo"
    networks:
      - backend_network
    depends_on:
      - rabbitmq
      - backend
    tty: true

  elasticsearch:
    build:
      context: ./elk/elasticsearch
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    restart: unless-stopped

  logstash:
    build:
      context: ./elk/logstash
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: changeme
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    build:
      context: ./elk/kibana
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - 5601:5601
    environment:
      KIBANA_SYSTEM_PASSWORD: changeme
    depends_on:
      - elasticsearch
    restart: unless-stopped

  filebeat:
    build:
      context: ./elk/filebeat
      args:
        ELASTIC_VERSION: 8.5.2
    entrypoint: "filebeat -e -strict.perms=false"
    volumes:
      - ./elk/filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - ./nginx/log:/var/log/nginx # nginx log path (require same option on nginx container)
    depends_on:
      - logstash
      - elasticsearch
      - kibana

networks:
  backend_network:
    driver: bridge
volumes:
  build_folder: null
  static_volume:
  # 인스턴스에 대해 데이터를 영구적으로 유지하기 위해 2개의 볼륨 사용
  prometheus_data: {}
  grafana_data: {}
  elasticsearch:
